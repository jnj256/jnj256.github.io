---
---

@string{aps = {American Physical Society,}}

@article{joshi2025mmrphys,
  author  = {Jitesh Joshi and Youngjun Cho},
  title   = {{Efficient and Robust Multidimensional Attention in Remote Physiological Sensing through Target Signal Constrained Factorization}},
  journal = {arXiv: 2505.07013 [cs.CV]},
  year    = {2025},
  abstract = {Remote physiological sensing using camera-based technologies offers transformative potential for non-invasive vital sign monitoring across healthcare and human-computer interaction domains. Although deep learning approaches have advanced the extraction of physiological signals from video data, existing methods have not been sufficiently assessed for their robustness to domain shifts. These shifts in remote physiological sensing include variations in ambient conditions, camera specifications, head movements, facial poses, and physiological states which often impact real-world performance significantly. Cross-dataset evaluation provides an objective measure to assess generalization capabilities across these domain shifts. We introduce Target Signal Constrained Factorization module (TSFM), a novel multidimensional attention mechanism that explicitly incorporates physiological signal characteristics as factorization constraints, allowing more precise feature extraction. Building on this innovation, we present MMRPhys, an efficient dual-branch 3D-CNN architecture designed for simultaneous multitask estimation of photoplethysmography (rPPG) and respiratory (rRSP) signals from multimodal RGB and thermal video inputs. Through comprehensive cross-dataset evaluation on five benchmark datasets, we demonstrate that MMRPhys with TSFM significantly outperforms state-of-the-art methods in generalization across domain shifts for rPPG and rRSP estimation, while maintaining a minimal inference latency suitable for real-time applications. Our approach establishes new benchmarks for robust multitask and multimodal physiological sensing and offers a computationally efficient framework for practical deployment in unconstrained environments. The live demo of its browser-based on-device deployment can be accessed on this URL: https://physiologicailab.github.io/mmrphys-live},
  preview = {MMRPhys.png},
  selected  = {true},
}

@article{rayhan2025advancing,
  title     = {Advancing textile damage segmentation: A novel RGBT dataset and thermal frequency normalization},
  author    = {Rayhan, Farshid and Joshi, Jitesh and Ren, Guangyu and Hernandez, Lucie and Petreca, Bruna and Baurley, Sharon and Berthouze, Nadia and Cho, Youngjun},
  journal   = {Sensors},
  volume    = {25},
  number    = {7},
  pages     = {2306},
  year      = {2025},
  publisher = {MDPI},
  preview   = {RGBT-Textile.png},
  abstract = {RGB-Thermal (RGBT) semantic segmentation is an emerging technology for identifying objects and materials in high dynamic range scenes. Thermal imaging particularly enhances feature extraction at close range for applications such as textile damage detection. In this paper, we present RGBT-Textile, a novel dataset specifically developed for close-range textile and damage segmentation. We meticulously designed the data collection protocol, software tools, and labeling process in collaboration with textile scientists. Additionally, we introduce ThermoFreq, a novel thermal frequency normalization method that reduces temperature noise effects in segmentation tasks. We evaluate our dataset alongside six existing RGBT datasets using state-of-the-art (SOTA) models. Experimental results demonstrate the superior performance of the SOTA models with ThermoFreq, highlighting its effectiveness in addressing noise challenges inherent in RGBT semantic segmentation across diverse environmental conditions. We make our dataset publicly accessible to foster further research and collaborations.}
}

@article{wang2025streaming,
  title     = {Streaming to Connect: Exploring How Social Connectedness Relates to Empathy Types and Physiological States in Remote Virtual Audiences},
  author    = {Wang, Katherine and Joshi, Jitesh and Cho, Youngjun},
  journal   = {Sensors},
  volume    = {25},
  number    = {3},
  pages     = {872},
  year      = {2025},
  publisher = {MDPI},
  preview   = {VR_Synchrony.png},
  abstract  = {Examining remote virtual audiences is a vital part of understanding social experiences in modern human–computer interaction contexts. Doing so raises intriguing questions about how these mediated connections relate to emotional and physiological states. The vagus nerve is central to socioemotional processing and physiological well-being, with its activation represented as vagally mediated heart rate variability (vmHRV). We examine how participants’ social connectedness to virtual partners relates to their experience of socioemotional competences and psychophysiological states while observing streamed gameplay. In this experimental study with 48 participants, we compared self-reported empathy, empathic concern, and continuously measured vmHRV (from a PPG sensor) during different types of gameplay. The results revealed that viewers who felt greater social connectedness to remote partners also felt more empathic concern (quantitative detail) and had significantly heightened vmHRV (quant detail) across all conditions compared to those who felt lower connectedness. These findings reveal that stronger feelings of connectedness to remote partners are associated with enhanced socioemotional competences and physiological well-being. This research highlights the intertwined nature of social connectedness, empathy, and physiological health, providing valuable insights for designing virtual platforms that foster deeper interpersonal connections and promote well-being.}
}

@inproceedings{joshi2024factorizephys,
  title={FactorizePhys: Matrix Factorization for Multidimensional Attention in Remote Physiological Sensing},
  author={Jitesh Joshi and Sos Agaian and Youngjun Cho},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024},
  url={https://openreview.net/forum?id=qrfp4eeZ47},
  abstract = {Remote photoplethysmography (rPPG) enables non-invasive extraction of blood volume pulse signals through imaging, transforming spatial-temporal data into time series signals. Advances in end-to-end rPPG approaches have focused on this transformation where attention mechanisms are crucial for feature extraction. However, existing methods compute attention disjointly across spatial, temporal, and channel dimensions. Here, we propose the Factorized Self-Attention Module (FSAM), which jointly computes multidimensional attention from voxel embeddings using nonnegative matrix factorization. To demonstrate FSAM's effectiveness, we developed FactorizePhys, an end-to-end 3D-CNN architecture for estimating blood volume pulse signals from raw video frames. Our approach adeptly factorizes voxel embeddings to achieve comprehensive spatial, temporal, and channel attention, enhancing performance of generic signal extraction tasks. Furthermore, we deploy FSAM within an existing 2D-CNN-based rPPG architecture to illustrate its versatility. FSAM and FactorizePhys are thoroughly evaluated against state-of-the-art rPPG methods, each representing different types of architecture and attention mechanism. We perform ablation studies to investigate the architectural decisions and hyperparameters of FSAM. Experiments on four publicly available datasets and intuitive visualization of learned spatial-temporal features substantiate the effectiveness of FSAM and enhanced cross-dataset generalization in estimating rPPG signals, suggesting its broader potential as a multidimensional attention mechanism. The code is accessible at https://github.com/PhysiologicAILab/FactorizePhys.},
  selected  = {true},
  preview = {FSAM.png}  
}


@article{joshi2024ibvp,
    title={iBVP Dataset: RGB-Thermal rPPG Dataset with High Resolution Signal Quality Labels},
    author={Joshi, Jitesh and Cho, Youngjun},
    journal={Electronics},
    publisher={MDPI},
    volume={13},
    year={2024},
    number={7},
    pages={1334},
    url={https://www.mdpi.com/2079-9292/13/7/1334},
    issn={2079-9292},
    abstract = {Remote photo-plethysmography (rPPG) has emerged as a non-intrusive and promising physiological sensing capability in human–computer interface (HCI) research, gradually extending its applications in health-monitoring and clinical care contexts. With advanced machine learning models, recent datasets collected in real-world conditions have gradually enhanced the performance of rPPG methods in recovering heart-rate and heart-rate-variability metrics. However, the signal quality of reference ground-truth PPG data in existing datasets is by and large neglected, while poor-quality references negatively influence models. Here, this work introduces a new imaging blood volume pulse (iBVP) dataset of synchronized RGB and thermal infrared videos with ground-truth PPG signals from ear with their high-resolution-signal-quality labels, for the first time. Participants perform rhythmic breathing, head-movement, and stress-inducing tasks, which help reflect real-world variations in psycho-physiological states. This work conducts dense (per sample) signal-quality assessment to discard noisy segments of ground-truth and corresponding video frames. We further present a novel end-to-end machine learning framework, iBVPNet, that features an efficient and effective spatio-temporal feature aggregation for the reliable estimation of BVP signals. Finally, this work examines the feasibility of extracting BVP signals from thermal video frames, which is under-explored. The iBVP dataset and source codes are publicly available for research use.},
    doi = {10.3390/electronics13071334},
    selected  = {true},
    preview = {iBVP_dataset.png}
}



@article{joshi2023physiokit,
  title={PhysioKit: An Open-Source, Low-Cost Physiological Computing Toolkit for Single-and Multi-User Studies},
  author={Joshi, Jitesh and Wang, Katherine and Cho, Youngjun},
  journal={Sensors},
  volume={23},
  number={19},
  pages={8244},
  year={2023},
  publisher={MDPI},
  url = {https://www.mdpi.com/1424-8220/23/19/8244},
  abstract = {The proliferation of physiological sensors opens new opportunities to explore interactions, conduct experiments and evaluate the user experience with continuous monitoring of bodily functions. Commercial devices, however, can be costly or limit access to raw waveform data, while low-cost sensors are efforts-intensive to setup. To address these challenges, we introduce PhysioKit, an open-source, low-cost physiological computing toolkit. PhysioKit provides a one-stop pipeline consisting of (i) a sensing and data acquisition layer that can be configured in a modular manner per research needs, and (ii) a software application layer that enables data acquisition, real-time visualization and machine learning (ML)-enabled signal quality assessment. This also supports basic visual biofeedback configurations and synchronized acquisition for co-located or remote multi-user settings. In a validation study with 16 participants, PhysioKit shows strong agreement with research-grade sensors on measuring heart rate and heart rate variability metrics data. Furthermore, we report usability survey results from 10 small-project teams (44 individual members in total) who used PhysioKit for 4–6 weeks, providing insights into its use cases and research benefits. Lastly, we discuss the extensibility and potential impact of the toolkit on the research community.},
  preview = {physiokit.png}
}

@inproceedings{Joshi_2022_BMVC,
author    = {Joshi, Jitesh and Bianchi-Berthouze, Nadia and Cho, Youngjun},
title     = {Self-adversarial Multi-scale Contrastive Learning for Semantic Segmentation of Thermal Facial Images},
booktitle = {33rd British Machine Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022},
publisher = {{BMVA} Press},
year      = {2022},
url       = {https://bmvc2022.mpi-inf.mpg.de/0864.pdf},
abstract  = {Segmentation of thermal facial images is a challenging task. This is because facial features often lack salience due to high-dynamic thermal range scenes and occlusion issues. Limited availability of datasets from unconstrained settings further limits the use of the state-of-the-art segmentation networks, loss functions and learning strategies which have been built and validated for RGB images. To address the challenge, we propose Self-Adversarial Multi-scale Contrastive Learning (SAM-CL framework as a new training strategy for thermal image segmentation. SAM-CL framework consists of a SAM-CL loss function and a thermal image augmentation (TiAug) module as a domain-specific augmentation technique. We use the Thermal-Face-Database to demonstrate effectiveness of our approach. Experiments conducted on the existing segmentation networks (UNET, Attention-UNET, DeepLabV3 and HRNetv2) evidence the consistent performance gains from the SAM-CL framework. Furthermore, we present a qualitative analysis with UBComfort and DeepBreath datasets to discuss how our proposed methods perform in handling unconstrained situations.},
selected  = {true},
preview   = {samcl.png}
}

@article{patent3Mml1,
 title={Detecting a condition for a culture device using a machine learning model},
 author={Tran, Thanh and Watson, Hugh and Joshi, Jitesh and SK, Abhilash and Tiwari, Rohitkumar},
 year={2021},
 journal={WIPO Patent WO2021234514A1},
 url={https://patents.google.com/patent/WO2021234514A1}
}

@article{patent3Mml2,
 title={Compensation of intensity variances in images used for colony enumeration},
 author={Tran, Thanh and Watson, Hugh and Joshi, Jitesh and Patel, Rinkeshkumar},
 year={2021},
 journal={WIPO Patent WO2021229337A1},
 url={https://patents.google.com/patent/WO2021229337A1}
 }

@article{patent3Moptics1,
 title={Imaging device with illumination components},
 author={Tran, Thanh and Watson, Hugh and Joshi, Jitesh},
 year={2021},
 journal={WIPO Patent WO2021229347A1},
 url={https://patents.google.com/patent/WO2021229347A1}
 }

@article{joshi2014boldsync,
  title={BOLDSync: A MATLAB-based toolbox for synchronized stimulus presentation in functional MRI},
  author={Joshi, Jitesh and Saharan, Sumiti and Mandal, Pravat K},
  journal={Journal of neuroscience methods},
  volume={223},
  pages={123--132},
  year={2014},
  publisher={Elsevier},
  preview = {BOLDSync.png}
}

@article{mandal2012visuospatial,
  title={Visuospatial perception: an emerging biomarker for Alzheimer's disease},
  author={Mandal, Pravat K and Joshi, Jitesh and Saharan, Sumiti},
  journal={Journal of Alzheimer's Disease},
  volume={31},
  number={s3},
  pages={S117--S135},
  year={2012},
  publisher={IOS Press},
  preview={visuospatial_perception.png}
}
